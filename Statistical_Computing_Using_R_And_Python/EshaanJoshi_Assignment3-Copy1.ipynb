{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a64c6e2b-faf0-46a2-8495-10f31d3523a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x<-10.5\n",
    "y<-55\n",
    "\n",
    "x\n",
    "\n",
    "y\n",
    "\n",
    "class(x)\n",
    "class(y)\n",
    "\n",
    "### Type Conversion\n",
    "You can convert from one type to another with the following functions:\n",
    "- `as.numeric()`\n",
    "- `as.integer()`\n",
    "- `as.complex()`\n",
    "\n",
    "x <- 1L #integer\n",
    "y <- 2 #numeric\n",
    "\n",
    "# convert from integer to numeric\n",
    "a <- as.numeric(x)\n",
    "a\n",
    "class(a)\n",
    "\n",
    "b <- as.integer(y)\n",
    "b\n",
    "class(b)\n",
    "\n",
    "max(5,10,15)\n",
    "\n",
    "min(5,10,15)\n",
    "\n",
    "sqrt(16)\n",
    "\n",
    "abs(-5)\n",
    "\n",
    "abs(-4.7)\n",
    "\n",
    "### Ceiling and Floor\n",
    "- The `ceiling()` function rounds a number upwards to its nearest integer, and the `floor()` function rounds a number downwards to its nearest integer\n",
    "\n",
    "ceiling(1.4)\n",
    "\n",
    "floor(1.4)\n",
    "\n",
    "ceiling(2.7)\n",
    "\n",
    "floor(2.7)\n",
    "\n",
    "### R Strings\n",
    "String Literals\n",
    "- A character, or strings are used for storing text. A string is surrounded by either single quotation marks, or double quotation marks.\n",
    "- `\"hello\"` is same as `'hello'`\n",
    "- Assigning a string to a variable is done with the variable followed by the `<-` operator and the string: `str <- \"Hello World!\"`\n",
    "\n",
    "str <- \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla in nisi id urna dapibus\n",
    "ullamcorper et eget libero. Fusce a faucibus purus. Praesent viverra diam eu venenatis dictum.\n",
    "Cras sit amet vestibulum dolor.\n",
    "Nulla condimentum scelerisque tellus a varius. Curabitur sit amet luctus nibh.\n",
    "Mauris bibendum sodales ex eget sodales. Nullam et velit neque.\n",
    "Sed ut urna vitae libero tempus pharetra nec nec sem.\n",
    "Quisque lectus ex, bibendum id mauris non, fermentum maximus ex. Sed non libero arcu.\"\n",
    "\n",
    "str\n",
    "\n",
    "cat(str)\n",
    "\n",
    "nchar(str)\n",
    "\n",
    "### Matrices\n",
    "- Matrix is a two dimensional data set with columns and rows\n",
    "- A column is a vertical representation of data, while a row is a horizontal representation of data.\n",
    "- A matrix can be created with the `matrix()` function. Specify the `nrow` and `ncol` parameters to get the amount of rows and columns\n",
    "\n",
    "matrix1 <- matrix(c(1,2,3,4,5,6),nrow=3,ncol=2)\n",
    "\n",
    "matrix1\n",
    "\n",
    "print(matrix1)\n",
    "\n",
    "matrix(c(1,2,3,4,5,6),nrow=3,ncol=2,byrow = TRUE)\n",
    "\n",
    "matrix2 <- matrix(c('apple','banana','cherry','orange'),nrow=2,ncol=2)\n",
    "\n",
    "matrix2\n",
    "\n",
    "print(matrix2)\n",
    "\n",
    "matrix3 <- matrix(c(\"apple\",'banana', 'cherry',\n",
    "                          'orange', 'grape','pineapple','pear','melon','fig'),\n",
    "                       nrow=3,ncol=3)\n",
    "\n",
    "matrix3\n",
    "\n",
    "#### Accessing multiple rows\n",
    "\n",
    "matrix3[c(1,2),]\n",
    "\n",
    "#### Accessing multiple columns\n",
    "\n",
    "matrix3[,c(1,2)]\n",
    "\n",
    "#### Adding rows and columns\n",
    "- Use `cbind()` to add columns\n",
    "- Use `rbind()` to add rows\n",
    "- **The cells in the new column / row must be of same length as the existing matrix**\n",
    "\n",
    "matrix3.1 <- cbind(matrix3,c(\"strawberry\",\"blueberry\",\"raspberry\"))\n",
    "\n",
    "print(matrix3.1)\n",
    "\n",
    "matrix3.2 = rbind(matrix3.1,c(\"mango\",\"litchee\",\"guava\",\"cranberry\"))\n",
    "\n",
    "print(matrix3.2)\n",
    "\n",
    "#### Removing Rows & Columns\n",
    "- Use the `c()` function to remove rows and columns in a matrix\n",
    "\n",
    "print(matrix3.2[-c(1),-c(1)])\n",
    "\n",
    "print(matrix3.2[-c(4),-c(4)])\n",
    "\n",
    "matrix4 <- matrix3.2[-c(4),-c(4)]\n",
    "\n",
    "print(matrix4)\n",
    "\n",
    "-----\n",
    "\n",
    "### Basic Syntax\n",
    "\n",
    "#### Mathematics\n",
    "\n",
    "1+1\n",
    "\n",
    "1-3\n",
    "\n",
    "1*5\n",
    "\n",
    "1/6\n",
    "\n",
    "x = 1\n",
    "y = 2\n",
    "x + y\n",
    "\n",
    "z = x + y\n",
    "z\n",
    "\n",
    "#### Trignometry\n",
    "\n",
    "tan(2)\n",
    "\n",
    "sin(2)\n",
    "\n",
    "cos(2)\n",
    "\n",
    "#### Statistics\n",
    "\n",
    "# Standard Deviation\n",
    "sd(c(1,2,3,4,5,6))\n",
    "\n",
    "# Mean\n",
    "mean(c(1,2,3,4,5,6))\n",
    "\n",
    "# Variance\n",
    "var(c(1,2,3,4,5,6))\n",
    "\n",
    "# Median\n",
    "median(c(1,2,3,4,5,6))\n",
    "\n",
    "# Minimum\n",
    "min(c(1,2,3,4,5,6))\n",
    "\n",
    "# Maximum\n",
    "max(c(1,2,3,4,5,6))\n",
    "\n",
    "plot(c(1,2,3,4,5,6))\n",
    "\n",
    "plot(c(1,2,3,4,5,6),c(2,3,4,5,6,7))\n",
    "\n",
    "### Data Types\n",
    "\n",
    "a <- \"abc\"\n",
    "\n",
    "b <- 1.2\n",
    "\n",
    "a+b\n",
    "\n",
    "paste(\"The data class of var a is\",class(a))\n",
    "paste(\"The data class of var b is\",class(b))\n",
    "\n",
    "a <- TRUE\n",
    "\n",
    "paste(\"The data class of var a is\",class(a))\n",
    "\n",
    "#### We can use `is.datatype()` to determine whether a variable is of a certain data type\n",
    "\n",
    "is.numeric(a)\n",
    "\n",
    "a <- 123\n",
    "\n",
    "is.numeric(a)\n",
    "\n",
    "b <- \"56\"\n",
    "\n",
    "is.numeric(b)\n",
    "\n",
    "is.character(b)\n",
    "\n",
    "a <- 12\n",
    "\n",
    "b <- \"56\"\n",
    "\n",
    "a+b\n",
    "\n",
    "b <- as.numeric(b)\n",
    "\n",
    "a+b\n",
    "\n",
    "`a <- 12` means that a is numeric data type. `b <- \"56\"` means that b is a character data type.\n",
    "When a and b are added together, you will get an error because you are adding a numeric data type to a character data type. If you try to convert b to the numeric data type using `b <- as.numeric(b)` you can add a and b together because a is a numeric data type and b is now a numeric data type also\n",
    "\n",
    "#### Vectors\n",
    "- A vector is a basic data structure or R object for storing a set of values of the same data type.\n",
    "- A vector is the most basic and common data structure in R.\n",
    "- A vector is used when you want to store and modify a set of values\n",
    "- Vectors can be created using the `c()` function as follows:\n",
    "\n",
    "a <- c(1,2,3,4,5,6)\n",
    "\n",
    "print(a)\n",
    "\n",
    "a <- 1:8\n",
    "\n",
    "print(a)\n",
    "\n",
    "#### Lists\n",
    "- List is like a vector\n",
    "\n",
    "a <- list(\"a\",'b',1,2)\n",
    "\n",
    "print(a)\n",
    "\n",
    "a\n",
    "\n",
    "#### Matrix\n",
    "- To create a matrix, we can use the following syntax:\n",
    "<br>`var <- matrix(vector,nrow=m,ncol=n)`\n",
    "\n",
    "a <- matrix(c(1,2,3,4,5,6,7,8,9),nrow=3,ncol=3)\n",
    "\n",
    "a\n",
    "\n",
    "print(a)\n",
    "\n",
    "a <- matrix(c(1,2,3,4,5,6,7,8,9),nrow=3,ncol=3,dimnames = list(c(\"x\",'y','z'),c('a','b','c')))\n",
    "\n",
    "a\n",
    "\n",
    "print(a)\n",
    "\n",
    "class(a)\n",
    "\n",
    "attributes(a)\n",
    "\n",
    "rownames(a)\n",
    "\n",
    "colnames(a)\n",
    "\n",
    "##### Creating matrix using `rbind()` and `cbind()`\n",
    "\n",
    "b <- cbind(c(1,2,3),c(4,5,6))\n",
    "\n",
    "b\n",
    "\n",
    "print(b)\n",
    "\n",
    "c <- rbind(c(1,2,3),c(4,5,6))\n",
    "\n",
    "c\n",
    "\n",
    "print(c)\n",
    "\n",
    "##### Transpose of a matrix\n",
    "\n",
    "print(a)\n",
    "\n",
    "print(t(a))\n",
    "\n",
    "#### DataFrames\n",
    "\n",
    "a <- data.frame(emp_id=c(1,2,3),names=c('John','James','Mary'),salary=c(111.1,222.2,333.3))\n",
    "\n",
    "print(a)\n",
    "\n",
    "a\n",
    "\n",
    "typeof(a)\n",
    "\n",
    "class(a)\n",
    "\n",
    "ncol(a)\n",
    "\n",
    "nrow(a)\n",
    "\n",
    "str(a)\n",
    "\n",
    "### Reading files\n",
    "\n",
    "#### CSV\n",
    "\n",
    "data <- read.csv('insurance.csv',header=TRUE,sep=',')\n",
    "\n",
    "data\n",
    "\n",
    "## head(data)\n",
    "\n",
    "#### Excel\n",
    "\n",
    "#### SPSS\n",
    "\n",
    "----\n",
    "\n",
    "## Reading a CSV File\n",
    "\n",
    "data <- read.csv('monthly_crude_oil_processed.csv',header=TRUE,sep=',')\n",
    "\n",
    "print(head(data))\n",
    "\n",
    "head(data)\n",
    "\n",
    "## Reading an Excel file (xlsx)\n",
    "\n",
    "library(xlsx)\n",
    "\n",
    "data_xl <- read.xlsx(\"importexport202223.xlsx\",sheetIndex = 1)\n",
    "\n",
    "print(head(data_xl))\n",
    "\n",
    "head(data_xl)\n",
    "\n",
    "## Reading a SPSS data file `.sav`\n",
    "\n",
    "library(foreign)\n",
    "\n",
    "data_sps <- read.spss('Orders.sav',to.data.frame = TRUE)\n",
    "\n",
    "print(head(data_sps))\n",
    "\n",
    "head(data_sps)\n",
    "\n",
    "-----\n",
    "\n",
    "## Descriptive Statistics\n",
    "\n",
    "a <- c(1,2,3,4,5,5,5,6,7,8)\n",
    "\n",
    "summary(a)\n",
    "\n",
    "mean(a)\n",
    "\n",
    "median(a)\n",
    "\n",
    "mode = function(vec){\n",
    "    y <- table(vec)\n",
    "    print(names(y)[which(y==max(y))])\n",
    "}\n",
    "\n",
    "mode(a)\n",
    "\n",
    "var(a)\n",
    "\n",
    "sd(a)\n",
    "\n",
    "## Generating Random Numbers\n",
    "\n",
    "set.seed(123)\n",
    "# The main point of using the seed is to reproduce a particular sequence of 'random' values from normal distribution\n",
    "\n",
    "### Normal Distribution\n",
    "\n",
    "b <- rnorm(100,3,0.5)\n",
    "\n",
    "b\n",
    "\n",
    "hist(b,breaks=15)\n",
    "\n",
    "### Binomial Distribution\n",
    "\n",
    "c <- rbinom(10000,100,0.5)\n",
    "\n",
    "c\n",
    "\n",
    "hist(c,breaks=20)\n",
    "\n",
    "library(dplyr)\n",
    "\n",
    "set.seed(69)\n",
    "\n",
    "var1 <- rnorm(100,2,1)\n",
    "var2 <- rnorm(100,3,1)\n",
    "var3 <- rnorm(100,3,2)\n",
    "\n",
    "data <- data.frame(var1,var2,var3)\n",
    "\n",
    "head(data)\n",
    "\n",
    "sample(data$var1,5,replace = TRUE)\n",
    "\n",
    "data(iris)\n",
    "\n",
    "summary(iris)\n",
    "\n",
    "str(iris)\n",
    "\n",
    "sample(iris$Sepal.Length,13,replace = TRUE)\n",
    "\n",
    "### Stratified Sampling\n",
    "\n",
    "Selecting 13 random samples from each class\n",
    "\n",
    "iris_sample <- iris %>% group_by(Species) %>% sample_n(13)\n",
    "\n",
    "iris_sample\n",
    "\n",
    "## Descriptive Statistics\n",
    "\n",
    "a <- c(1,2,3,4,5,5,5,6,7,8)\n",
    "\n",
    "summary(a)\n",
    "\n",
    "mean(a)\n",
    "\n",
    "mean(var1)\n",
    "\n",
    "mean(var2)\n",
    "\n",
    "mean(var3)\n",
    "\n",
    "median(a)\n",
    "\n",
    "median(var1)\n",
    "\n",
    "mode = function(vec){\n",
    "    y <- table(vec)\n",
    "    print(names(y)[which(y==max(y))])\n",
    "}\n",
    "\n",
    "mode(a)\n",
    "\n",
    "var(a)\n",
    "\n",
    "sd(a)\n",
    "\n",
    "range(a)\n",
    "\n",
    "diff(range(a))\n",
    "\n",
    "min(a)\n",
    "\n",
    "max(a)\n",
    "\n",
    "paste('Range is:',min(a),\",\",max(a))\n",
    "\n",
    "max(a)-min(a)\n",
    "\n",
    "IQR(a)\n",
    "\n",
    "quantile(a)\n",
    "\n",
    "qqnorm(data$var1)\n",
    "qqline(data$var1)\n",
    "\n",
    "qqnorm(data$var2)\n",
    "qqline(data$var2)\n",
    "\n",
    "qqnorm(data$var3)\n",
    "qqline(data$var3)\n",
    "\n",
    "export_data <- read.csv('importexport202223.csv')\n",
    "\n",
    "head(export_data)\n",
    "\n",
    "qqnorm(export_data$APRIL)\n",
    "qqline(export_data$APRIL)\n",
    "\n",
    "IF p is low null will go, if p is high then we accept null\n",
    "\n",
    "## Shapiro-Wilk Normality test\n",
    "\n",
    "shapiro.test(data$var1)\n",
    "\n",
    "shapiro.test(data$var2)\n",
    "\n",
    "shapiro.test(data$var3)\n",
    "\n",
    "hist(data$var1)\n",
    "\n",
    "hist(data$var2)\n",
    "\n",
    "hist(data$var3)\n",
    "\n",
    "## CDF\n",
    "\n",
    "- To calculate the cumulative distribution function (CDF), F(x) = P(X <= x) where X is normal, we use pnorm() function:<br>\n",
    "`pnorm(1.9,3,0.5)` Above is a direct lookup for the probability P(X<1.9) where X is a normal distribution with mean of 3 and standard deviation of 0.5.<br> If we want P(X>1.9) we use `1-pnorm(1.9,3,0.5)`\n",
    "- If we want to calculate the inverse CDF and lookup for p-th quantile of the normal distribution, we use:<br>\n",
    "`qnorm(0.95,3,0.5)` This code looks for 95 percentile of the normal distribution with a standard deviation of 0.5 and a mean of 3. The value returned is an x value, not a probability.\n",
    "\n",
    "pnorm(6.9,4,0.2)\n",
    "\n",
    "qnorm(0.98,4,0.2)\n",
    "\n",
    "## Binomial Distribution\n",
    "\n",
    "### Probability Mass Function\n",
    "\n",
    "- Binomial distribution has two outcomes, success or failure, and can be thought of as the probability of success or failure in a survey that is repeated various times. The number of observations is fixed and each observation or probability is independent and the probability of success is the same for all observations.\n",
    "- To get the probability mass function P(X=x), of binomial distribution we can use the `dbinom()` function.\n",
    "\n",
    "dbinom(32,100,0.5)\n",
    "\n",
    "The above code lookup is for P(X=32) where X is the binomial distribution with a size of 100 and a probability of success is 0.5\n",
    "\n",
    "### Cumulative Distribution Function\n",
    "\n",
    "- To get the cumulative distribution function P(X<=x) of a binomial distribution we can use `pbinom()` function\n",
    "\n",
    "pbinom(32,100,0.5)\n",
    "\n",
    "The above code lookup is for p(X <= 32) where X is the binomial distribution with a size of 100 and a probability fo success of 0.5\n",
    "\n",
    "### P<sup>th</sup> quantile\n",
    "\n",
    "- To get the p-th quantile of the binomial distribution, we can use the `qbinom()` function\n",
    "\n",
    "qbinom(0.3,100,0.5)\n",
    "\n",
    "The above code lookup is for the 30<sup>th</sup> quantile of the binomial distribution where the size is 100 and the probability of success is 0.5. The value is a cumulative value.\n",
    "\n",
    "### Generating random variables\n",
    "\n",
    "- To generate random variables from a binomial distribution, we can use the `rbinom()` function\n",
    "\n",
    "set.seed(420)\n",
    "\n",
    "a <- rbinom(1000,100,0.5)\n",
    "\n",
    "hist(a,breaks=20)\n",
    "\n",
    "hist(a,breaks=15)\n",
    "\n",
    "hist(a,breaks=30)\n",
    "\n",
    "We can use the `rbinom()` or `rnorm()` to generate random variables to simulate a new dataset\n",
    "\n",
    "## `Summary()` and `str()` functions\n",
    "\n",
    "- The `summary()` and `str()` functions are the fastest wat to get descriptive statistics of the data. The `summary()` function gives the basic descriptive statistics of the data. The `str()` function, gives the structure of the variables.\n",
    "\n",
    "summary(data)\n",
    "\n",
    "str(data)\n",
    "\n",
    "## Correlations\n",
    "\n",
    "- Correlations are statistical associations to find how close two variables are and to derive the linear relationship between them. In predictive analytics, you can use correlation to find which variables are more related to the target variable and use this to reduce the number of variables. Correlation does not mean a casual relationship. Correlation finds how close two variables are, but does not tell you the how and why of the relationship. Causation tells you that one variable change will cause another variable to change.\n",
    "\n",
    "iris_data <- data.frame(iris)\n",
    "\n",
    "colnames(iris)\n",
    "\n",
    "col_names\n",
    "\n",
    "col_names = length(colnames(iris))-1\n",
    "for(i in 1:col_names)\n",
    "    {\n",
    "    for (j in i+1:col_names-i)\n",
    "    {\n",
    "        print(paste(\"Correlation between\",colnames(iris_data)[[i]],\"and\",colnames(iris_data)[[j]]))\n",
    "        print(cor(iris_data[,colnames(iris_data)[[i]]],iris_data[,colnames(iris_data)[[j]]]))\n",
    "    }\n",
    "}\n",
    "\n",
    "cor(data$var1,data$var2)\n",
    "\n",
    "The correlation has a range from -1.0 to 1.0, when the correlation is 0, there is no correlation or relationship. When the correlation is more than 0, it is a positive relationship. Positive correlation means that wehn one variable's value increases, the other variable's values also increase. When the correlation is less than 0, it is a negative relationship. Negative correlation means that when one variable's value increases, the other variable's value decreases. 1 is the perfect positive correlation and -1 is the perfect negative correlation. Hence, the larger the value towards 1, or smaller the value towards -1, the better the relationship.\n",
    "**-0.0671436526092431** means that the correlation between var1 and var2 is a negative correlation, as it is closed to zero the relationship is not good\n",
    "\n",
    "cor(data$var1,data$var3)\n",
    "\n",
    "The correlation has a range from -1.0 to 1.0, when the correlation is 0, there is no correlation or relationship. When the correlation is more than 0, it is a positive relationship. Positive correlation means that wehn one variable's value increases, the other variable's values also increase. When the correlation is less than 0, it is a negative relationship. Negative correlation means that when one variable's value increases, the other variable's value decreases. 1 is the perfect positive correlation and -1 is the perfect negative correlation. Hence, the larger the value towards 1, or smaller the value towards -1, the better the relationship.\n",
    "**0.0713532054580629** means that the correlation between var1 and var3 is a positive correlation, as it is closed to zero the relationship is not good\n",
    "\n",
    "cor(data$var2,data$var3)\n",
    "\n",
    "The correlation has a range from -1.0 to 1.0, when the correlation is 0, there is no correlation or relationship. When the correlation is more than 0, it is a positive relationship. Positive correlation means that wehn one variable's value increases, the other variable's values also increase. When the correlation is less than 0, it is a negative relationship. Negative correlation means that when one variable's value increases, the other variable's value decreases. 1 is the perfect positive correlation and -1 is the perfect negative correlation. Hence, the larger the value towards 1, or smaller the value towards -1, the better the relationship.\n",
    "**-0.0796639546553364** means that the correlation between var2 and var3 is a negative correlation, as it is closed to zero the relationship is not good\n",
    "\n",
    "## Covariance\n",
    "\n",
    "Covariance is a measure of variability between two varaibles. The greater the value of one variable and the greater of other variable means it will result in a covariance that is positive. The greater value of one variable to the lesser value of the other variable will result in a negative covariance. Covariance shows the linear relationship between both variables, but the covariance magnitude is difficult to interpret.\n",
    "\n",
    "col_names = length(colnames(iris))-1\n",
    "for(i in 1:col_names)\n",
    "    {\n",
    "    for (j in i+1:col_names-i)\n",
    "    {\n",
    "        print(paste(\"Covariance between\",colnames(iris_data)[[i]],\"and\",colnames(iris_data)[[j]]))\n",
    "        print(cov(iris_data[,colnames(iris_data)[[i]]],iris_data[,colnames(iris_data)[[j]]]))\n",
    "    }\n",
    "}\n",
    "\n",
    "cov(data$var1,data$var2)\n",
    "\n",
    "Correlation has a range of -1 to 1. Covariance does not have a range. Correlation is good for measuring how good the relationship between two variables in. When two variables have a positive covariance, when one variable increases, the other variables increases. When two variables have a negative covariance, when one variable increases, the other variable decreases. When two variable are independent of each other the covariance is zero.<br>\n",
    "-0.0585462183730391 means the covariance is negative, and it is very close to zero, so the relationship between the two variables is not very good. Correlation and covariance are usually within descriptive statistics\n",
    "\n",
    "cov(data$var1,data$var3)\n",
    "\n",
    "Correlation has a range of -1 to 1. Covariance does not have a range. Correlation is good for measuring how good the relationship between two variables in. When two variables have a positive covariance, when one variable increases, the other variables increases. When two variables have a negative covariance, when one variable increases, the other variable decreases. When two variable are independent of each other the covariance is zero.<br>\n",
    "0.136573405993444 means the covariance is positive, and it is very close to zero, so the relationship between the two variables is not very good. Correlation and covariance are usually within descriptive statistics\n",
    "\n",
    "cov(data$var2,data$var3)\n",
    "\n",
    "Correlation has a range of -1 to 1. Covariance does not have a range. Correlation is good for measuring how good the relationship between two variables in. When two variables have a positive covariance, when one variable increases, the other variables increases. When two variables have a negative covariance, when one variable increases, the other variable decreases. When two variable are independent of each other the covariance is zero.<br>\n",
    "-0.156280168159263 means the covariance is negative, and it is very close to zero, so the relationship between the two variables is not very good. Correlation and covariance are usually within descriptive statistics\n",
    "\n",
    "-----\n",
    "\n",
    "## Histogram\n",
    "\n",
    "|Life of tyre (in '000kms)|15-20|20-25|25-30|30-35|35-40|40-45|45-50|\n",
    "|:-----------------------:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "|No.of tyres|5|8|13|20|14|6|4|\n",
    "\n",
    "Note: In seq statement second number can be any number between 47.5 and 50\n",
    "<br>Since width of class is 5 ie w = 5\n",
    "\n",
    "x <- seq(17.5,48.5,5)\n",
    "\n",
    "w <- 5\n",
    "\n",
    "f <- c(5,8,13,20,14,6,4)\n",
    "\n",
    "lb <- (x-w)/2\n",
    "ub <- (x+w)/2\n",
    "\n",
    "brks <- c(lb[1],ub)\n",
    "\n",
    "y <- rep(x,f)\n",
    "\n",
    "y\n",
    "\n",
    "hist(y)\n",
    "\n",
    "hist(y,xlab=\"Life of tyre\",ylab=\"Number of tyres\",main=\"Histogram\")\n",
    "\n",
    "#### We can impose frequency curve on histogram by adding line statement\n",
    "\n",
    "hist(y,xlab=\"Life of tyre\",ylab=\"Number of tyres\",main=\"Histogram\")\n",
    "lines(x,f)\n",
    "\n",
    "## Frequency Curve\n",
    "\n",
    "x <- seq(17.5,47.5,5)\n",
    "\n",
    "f <- c(5,8,13,20,14,6,4)\n",
    "\n",
    "plot(x,f,\"l\",xlab=\"Life of tyre\",ylab=\"Number of tyres\",main='Frequency curve')\n",
    "\n",
    "plot(x,f,xlab=\"Life of tyre\",ylab=\"Number of tyres\",main='Frequency curve')\n",
    "\n",
    "## Frequency Polygon\n",
    "- For frequency polygon we have to add one extra point to the starting and ending in x and for f we have to add 0 in starting and ending\n",
    "\n",
    "x <- seq(12.5,52.5,5)\n",
    "\n",
    "f <- c(0,5,8,13,20,14,6,4,0)\n",
    "\n",
    "plot(x,f,\"l\",xlab=\"Life of tyre\",ylab=\"Number of tyres\",main=\"Frequency Polygon\")\n",
    "\n",
    "plot(x,f,\"l\",xlab=\"Life of tyre\",ylab=\"Number of tyres\",main=\"Frequency Polygon\")\n",
    "points(x,f,pch=16)\n",
    "\n",
    "plot(x,f,\"l\",xlab=\"Life of tyre\",ylab=\"Number of tyres\",main=\"Frequency Polygon\")\n",
    "points(x,f,pch=25)\n",
    "\n",
    "plot(x,f,\"l\",xlab=\"Life of tyre\",ylab=\"Number of tyres\",main=\"Frequency Polygon\")\n",
    "points(x,f,pch=69)\n",
    "\n",
    "plot(x,f,\"l\",xlab=\"Life of tyre\",ylab=\"Number of tyres\",main=\"Frequency Polygon\")\n",
    "points(x,f,pch=34)\n",
    "\n",
    "## Less tha type ogive\n",
    "\n",
    "x <- seq(17.5,48.5,5)\n",
    "\n",
    "f <- c(0,5,8,13,20,14,6,4)\n",
    "\n",
    "lb <- x-w/2\n",
    "ub <- x+w/2\n",
    "\n",
    "k <- length(x)\n",
    "\n",
    "lb1 <- c(lb,50)\n",
    "ub1 <- c(15,ub)\n",
    "\n",
    "lcf <- cumsum(f)\n",
    "\n",
    "plot(ub1,lcf,\"l\",xlim=c(15,50),xlab='Class limits',ylab='cumfreq',\n",
    "     main='Less than ogive',lwd=2)\n",
    "points(ub1,lcf,pch=16)\n",
    "# lwd is used for line and for width of line\n",
    "\n",
    "## More than type ogive\n",
    "\n",
    "x <- seq(17.5,48.5,5)\n",
    "\n",
    "f <- c(0,5,8,13,20,14,6,4)\n",
    "\n",
    "lb <- x-w/2\n",
    "ub <- x+w/2\n",
    "\n",
    "k <- length(x)+1\n",
    "\n",
    "lb1 <- c(lb,50)\n",
    "ub1 <- c(15,ub)\n",
    "\n",
    "mcf <- 1:k\n",
    "\n",
    "for(i in 1:k)\n",
    "    {\n",
    "    mcf[i] = sum(f[k:i])\n",
    "}\n",
    "\n",
    "plot(lb1,mcf,\"l\",xlim=c(15,50),xlab='Class limits',ylab='cumfreq',\n",
    "     main='More than ogive',lwd=2)\n",
    "points(lb1,mcf,pch=16)\n",
    "# lwd is used for line and for width of line\n",
    "\n",
    "## Boxplot\n",
    "\n",
    "x <- c(0,12,14,17,22,7,11,29,21,20,30,15,17,12,16,9,8,12,16,9,8,12,16,9,8,12,23,26,14,19)\n",
    "\n",
    "boxplot(x)\n",
    "\n",
    "boxplot(x,ylab='Marks')\n",
    "\n",
    "boxplot(x,ylab='Marks')\n",
    "f = fivenum(x)\n",
    "text(rep(1.3,5),f,labels=c('Minimum','1st Quartile','Median','3rd Quartile','Maximum'))\n",
    "\n",
    "------\n",
    "\n",
    "x <- c(0,12,14,17,22,7,11,29,21,20,30,15,17,12,16,9,8,12,16,9,8,12,16,9,8,12,23,26,14,19,100)\n",
    "\n",
    "boxplot(x)\n",
    "\n",
    "boxplot(x,ylab='Marks')\n",
    "\n",
    "boxplot(x,ylab='Marks')\n",
    "f = fivenum(x)\n",
    "text(rep(1.3,5),f,labels=c('Minimum','1st Quartile','Median','3rd Quartile','Maximum'))\n",
    "\n",
    "## Pie chart\n",
    "\n",
    "Represent the data by pie diagram\n",
    "|Item|% expenses|\n",
    "|:--:|:--------:|\n",
    "|Food|25|\n",
    "|Rent|18|\n",
    "|Cloths|22|\n",
    "|Travel|20|\n",
    "|Misc|15|\n",
    "\n",
    "i <- c(\"Food\",\"Rent\",\"Cloths\",\"Travel\",\"Misc\")\n",
    "e <- c(25,18,22,20,15)\n",
    "\n",
    "pie(e,radius=1)\n",
    "\n",
    "pie(e,main='Percentage Expenses',col=3:7,labels=i) #Labels added, for specific colours use col\n",
    "\n",
    "pie(e,main='Percentage Expenses',col=1:7,labels=i) #Labels added, for specific colours use col\n",
    "\n",
    "#### Homework\n",
    "Draw a histogram, frequency curve, frequency polygon, less than ogive curve, more than ogive curve of the following data.\n",
    "\n",
    "x = View(airquality)\n",
    "\n",
    "str(airquality)\n",
    "\n",
    "sum(is.na(airquality))\n",
    "\n",
    "temperature <- airquality$Temp\n",
    "\n",
    "hist(temperature, main=\"Maximum daily temperature at La Guardia Airport\",xlab='Temperature in degrees Farenheit',\n",
    "    xlim=c(50,100),col='grey',freq=FALSE)\n",
    "# Creating histogram considering density instead of frequency, in this case the total area of the histogram is 1\n",
    "\n",
    "hist(airquality$Solar.R, main=\"Maximum daily temperature at La Guardia Airport\",xlab='Temperature in degrees Farenheit',\n",
    "    xlim=c(0,350),col='grey',freq=FALSE)\n",
    "# Creating histogram considering density instead of frequency, in this case the total area of the histogram is 1\n",
    "\n",
    "hist(temperature, main=\"Maximum daily temperature at La Guardia Airport with 4 breaks\",xlab='Temperature in degrees Farenheit',\n",
    "    breaks=4,col='grey',freq=FALSE)\n",
    "# Creating histogram considering density instead of frequency, in this case the total area of the histogram is 1\n",
    "\n",
    "With the breaks argument we can specify the number of cells\n",
    "\n",
    "hist(temperature, main=\"Maximum daily temperature at La Guardia Airport with 20 breaks\",xlab='Temperature in degrees Farenheit',\n",
    "    breaks=20,col='grey',freq=FALSE)\n",
    "# Creating histogram considering density instead of frequency, in this case the total area of the histogram is 1\n",
    "\n",
    "------\n",
    "\n",
    "## Q1\n",
    "Draw a histogram, frequency curve, frequency polygon, less than type ogive, more than type ogive curve of the following data.\n",
    "\n",
    "||||||||||\n",
    "|:----------:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "|Sales (0'00)|20-25|25-30|30-35|35-40|40-45|45-50|50-55|55-60|\n",
    "|No.of days|5|9|13|28|20|12|10|3|\n",
    "\n",
    "sales <- seq(22.5,57.5,5)\n",
    "\n",
    "w <- 5\n",
    "\n",
    "freq <- c(5,9,13,28,20,12,10,3)\n",
    "\n",
    "### Histogram\n",
    "\n",
    "y <- rep(sales,freq)\n",
    "\n",
    "hist(y,xlab=\"Sales\",ylab=\"Number of days\",main=\"Histogram\")\n",
    "\n",
    "### Frequency Curve\n",
    "\n",
    "plot(sales,freq,'l',xlab='Sales',ylab='Number of days',\n",
    "     main='Frequency Curve')\n",
    "\n",
    "### Frequency Polygon\n",
    "\n",
    "sales <- seq(17.5,62.5,5)\n",
    "freq <- c(0,5,9,13,28,20,12,10,3,0)\n",
    "\n",
    "plot(sales,freq,'l',xlab='Sales',ylab='Number of days',\n",
    "     main='Frequency Polygon')\n",
    "points(sales,freq,pch=16)\n",
    "\n",
    "### Less than ogive\n",
    "\n",
    "sales <- seq(22.5,57.5,5)\n",
    "freq <- c(0,5,9,13,28,20,12,10,3)\n",
    "\n",
    "lb <- sales-w/2\n",
    "ub <- sales+w/2\n",
    "\n",
    "k <-length(sales)\n",
    "\n",
    "lb1 <- c(lb,60)\n",
    "ub1 <- c(20,ub)\n",
    "\n",
    "lcf <- cumsum(freq)\n",
    "\n",
    "plot(ub1,lcf,'l',xlim=c(20,60),xlab='Class Limits',\n",
    "     ylab='Cumulative Frequency',main='Less than ogive',lwd=2)\n",
    "points(ub1,lcf,pch=16)\n",
    "\n",
    "### More than ogive\n",
    "\n",
    "sales <- seq(22.5,57.5,5)\n",
    "freq <- c(0,5,9,13,28,20,12,10,3)\n",
    "\n",
    "lb <- sales-w/2\n",
    "ub <- sales+w/2\n",
    "\n",
    "k <-length(sales)+1\n",
    "\n",
    "lb1 <- c(lb,60)\n",
    "ub1 <- c(20,ub)\n",
    "\n",
    "mcf <- 1:k\n",
    "\n",
    "for (i in 1:k)\n",
    "    {\n",
    "    mcf[i] = sum(freq[k:i])\n",
    "}\n",
    "\n",
    "plot(lb1,mcf,'l',xlim=c(20,60),xlab='Class Limits',\n",
    "     ylab='Cumulative Frequency',main='More than ogive',lwd=2)\n",
    "points(lb1,mcf,pch=16)\n",
    "\n",
    "## Q2\n",
    "The following figures relate to the cost of construction of a house in a city.\n",
    "\n",
    "||||||||\n",
    "|:--:|:----:|:---:|:----:|:----:|:----:|:-----------:|\n",
    "|Item|Cement|Steel|Bricks|Timber|Labour|Miscellaneous|\n",
    "|% Expenditure|20|18|10|15|25|12|\n",
    "\n",
    "Present the data with the help of a suitable diagram\n",
    "\n",
    "item <- c('Cement','Steel','Bricks','Timber','Labour','Miscellaneous')\n",
    "expenditure_per <- c(20,18,10,15,25,12)\n",
    "\n",
    "pie(expenditure_per,col = 3:8,labels = item,\n",
    "    main='Cost Distribution of house construction')\n",
    "\n",
    "## Q3\n",
    "The following data give the daily expenses of 40 school children from a certain locality\n",
    "```\n",
    "21,50,35,39,48,46,36,54,42,30,29,42,32,40,34,\n",
    "31,35,37,52,44,39,42,32,40,34,31,100\n",
    "```\n",
    "\n",
    "Draw boxplot and write conclusion\n",
    "\n",
    "expenses <- c(21,50,35,39,48,46,36,54,42,30,29,42,32,40,34,\n",
    "              31,35,37,52,44,39,42,32,40,34,31,100)\n",
    "\n",
    "boxplot(expenses,ylab='Expenses')\n",
    "summ <- fivenum(expenses)\n",
    "text(rep(1.3,5),summ,\n",
    "labels = c('Minimum','1st Quartile','Median','3rd Quartile','Maximum'))\n",
    "\n",
    "- There is one outlier in the given data, as the data point is higher than the upper bound.\n",
    "- Median expense is 39\n",
    "- Average expense is ~40.56\n",
    "- Minimum expense is 21 and maximum expense is 100\n",
    "- 1st Quantile value is 33, 3rd Quantile value is 43\n",
    "\n",
    "----\n",
    "\n",
    "## Hypothesis Testing and P-Value\n",
    "\n",
    "- A hypothesis can also be a null hypothesis, H<sub>0</sub>, and an alternate hypothesis, H<sub>1</sub>. You can write the null hypothesis and alternate hypothesis as follows:<br>\n",
    "H<sub>0</sub>: μ<sub>1</sub> = μ<sub>2</sub><br>\n",
    "H<sub>1</sub>: μ<sub>1</sub> != μ<sub>2</sub>\n",
    "where μ<sub>1</sub> is the mean of one data and μ<sub>2</sub> is the mean of another data. We can use statistical tests to get your p-value. We use a t-test for continuous variables or data and a chi-square test for categorical variables or data. For more complex testing, you use ANOVA. If data is not normally distributed, use non-parametric tests.<br>\n",
    "A P-value helps to determine the significance of statistical test results. A small p-value < alpha, which is usually 0.05, indicated that the observed data is sufficiently inconsistent with the null hypothesis, so the null hypothesis may be rejected. The alternate hypothesis is true at 95% confidence interval. A larger p-value means that we failed to reject null hypothesis.\n",
    "\n",
    "### T-Test\n",
    "\n",
    "A t-test is one of the more important tests in statistics. A t-test is used to determine whether the mean between two data points or samples are equal to each other.\n",
    "H<sub>0</sub>: μ<sub>1</sub> = μ<sub>2</sub><br>\n",
    "H<sub>1</sub>: μ<sub>1</sub> != μ<sub>2</sub>\n",
    "\n",
    "#### Types of t-test\n",
    "\n",
    "##### One-Sample Test\n",
    "- To use a one-sample t-test in R, you can use the `t.test()` function\n",
    "\n",
    "set.seed(123)\n",
    "\n",
    "var1 <- rnorm(100,mean=2,sd=1)\n",
    "var2 <- rnorm(100,mean=3,sd=1)\n",
    "var3 <- rnorm(100,mean=3,sd=2)\n",
    "\n",
    "data <- data.frame(var1,var2,var3)\n",
    "\n",
    "t.test(data$var1,mu=0.6)\n",
    "\n",
    "H<sub>0</sub>: μ<sub>1</sub> = m<br>\n",
    "H<sub>1</sub>: μ<sub>1</sub> != m<br>\n",
    "m is 0.6, The p-value is 2.2e<sup>-16</sup>, so the p-value is less than 0.05, which is the alpha value. Therefore, the null hypothesis can be rejected. The alternate hypothesis, μ != 0.6 is true at 95% confidence interval.\n",
    "\n",
    "###### Q2\n",
    "\n",
    "x <- c(5,3,4,3,2,6,3,2,3,6,7,5,3)\n",
    "\n",
    "x\n",
    "\n",
    "t.test(x)\n",
    "\n",
    "m is 0, the p-value is 1.347e<sup>-6</sup>, therefore we can reject the null hypothesis. Therefore the alternate hypothesis μ != 0 is true at 95% interval.\n",
    "\n",
    "###### Q3\n",
    "- We have collected a random sample of 31 energy bars from a number of different stores to represent the population of energy bars available to the general consumer. The labels on the bars claim that each bar contains 20 grams of protein.\n",
    "\n",
    "x <- c(20.70,20.75,22.14,19.72,25.06,27.46,22.91,19.56,18.28,22.44,22.15,25.34,21.10,16.26,19.08,19.85,20.33,18.04,\n",
    "       17.46,19.88,21.29,21.54,24.12,20.53,21.39,24.75,21.08,19.95,22.12,22.33,25.79)\n",
    "\n",
    "t.test(x,mu=20)\n",
    "\n",
    "###### Q4\n",
    "We have the potato yield from 12 different farms. We know that the standard potato yield for the given variety is mu=20. Test the potato yield from these farms is significantly better than the standard yield.<br>\n",
    "H<sub>0</sub>: mu=20\n",
    "H<sub>1</sub>: mu > 20\n",
    "\n",
    "x <- c(21.5,24.5,18.5,17.2,14.5,23.2,22.1,20.5,19.4,18.1,24.1,18.5)\n",
    "\n",
    "t.test(x,mu=20,alternative = 'greater')\n",
    "\n",
    "##### Two Sampled T-Test\n",
    "The two sample unpaired t-test is when you compare two means of two independent samples. To use a two-sample unpaired t-test with a variance as equal in R:<br>\n",
    "To test:<br>\n",
    "H<sub>0</sub>: muA - muB = 0<br>\n",
    "H<sub>1</sub>: muA - muB != 0\n",
    "\n",
    "set.seed(123)\n",
    "\n",
    "var1 <- rnorm(100,mean=2,sd=1)\n",
    "var2 <- rnorm(100,mean=3,sd=1)\n",
    "var3 <- rnorm(100,mean=3,sd=2)\n",
    "\n",
    "data <- data.frame(var1,var2,var3)\n",
    "\n",
    "t.test(data$var1,data$var2,var.equal = TRUE,paired = FALSE)\n",
    "\n",
    "- The p-value is 7.843e<sup>-0</sup> so it is less than 0.05, so we can reject the null hypothesis\n",
    "\n",
    "###### Q1\n",
    "A group of men and women who did workouts at a gym three times a week for a year. Then, their trainer measured the body fat. The table below shows the data\n",
    "\n",
    "|Group|Body Fat Percentages|\n",
    "|:---:|:------------------:|\n",
    "|Men|13.3|6.0|20.0|8.0|14.0|19.0|18.0|25.0|16.0|24.0|15.0|1.0|15.0|\n",
    "|Women|22.0|16.0|21.7|21.0|30.0|26.0|12.0|23.2|28.0|23.0|\n",
    "\n",
    "Check whether the underlying populations of men and women at the gym have the same mean body fat.\n",
    "\n",
    "men <- c(13.3,6.0,20.0,8.0,14.0,19.0,18.0,25.0,16.0,24.0,15.0,1.0,15.0)\n",
    "women <- c(22.0,16.0,21.7,21.0,30.0,26.0,12.0,23.2,28.0,23.0)\n",
    "\n",
    "t.test(men,women,var.equal=TRUE,paired=FALSE)\n",
    "\n",
    "----\n",
    "\n",
    "x <- rnorm(1000,mean=1,sd=1)\n",
    "\n",
    "y <- rnorm(1000,mean=2,sd=2)\n",
    "\n",
    "data <- data.frame(x,y)\n",
    "\n",
    "mod <- lm(data$y ~ data$x,data=data)\n",
    "\n",
    "mod\n",
    "\n",
    "summary(mod)\n",
    "\n",
    "- The output depicts that the linear equation is y = 0.01128x + 2.01385\n",
    "- The p-values of <2e<sup>-16</sup>, 0.868 which tell you the significance of the linear model. When the p-value is less than 0.05 the model is significant.\n",
    "<br>**Hypothesis**\n",
    "- H<sub>o</sub>: Coefficient associated with the variable is equal to zero\n",
    "- H<sub>1</sub>: Coefficient is not equal to zero (there is a relationship)\n",
    "<br>The intercept has a p-value of <2e<sup>-16</sup>, which is smaller than 0.05 so there is significance with the y-variable. The significance is indicated with the number of `*`. The x has a p-value of 0.868, which is more than 0.05 so there is no significance with the y-variable. The null hypothesis is true at 95% confidence interval. R-square depicts the proportion of the variation in the dependent variable.\n",
    "<br>Hence the higher the R-squared and the adjusted R-squared the better the linear model. The lower the standard error, the better the model\n",
    "\n",
    "## Q1. The data regarding the production of wheat in tons (X) and the price of the kilo of flour (Y) in the decade of the 80's in Spain were:\n",
    "\n",
    "||||||||||||\n",
    "|:--------------:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|\n",
    "|Wheat Production|30|28|32|25|25|25|22|24|35|40|\n",
    "|Flour Price|25|30|27|40|42|40|50|45|30|25|\n",
    "\n",
    "a. Fit the regression line using the method of least squares\n",
    "<br>b. Compute a 95% confidence interval for the slope of the regression line\n",
    "<br>c. Text the hypothesis that the price of flour depends linearly on the wheat production\n",
    "\n",
    "wheat_prod = c(30,28,32,25,25,25,22,24,35,40)\n",
    "\n",
    "flour_price = c(25,30,27,40,42,40,50,45,30,25)\n",
    "\n",
    "data = data.frame(wheat_prod,flour_price)\n",
    "\n",
    "mod_lm = lm('flour_price ~ wheat_prod',data=data)\n",
    "\n",
    "mod_lm\n",
    "\n",
    "summary(mod_lm)\n",
    "\n",
    "- The output depicts the linear equation is y = -1.3537x + 74.1151\n",
    "- The p-values of 2.85e<sup>-05</sup>, 0.00198 tell the significance of the model, when less than 0.05 it is significant\n",
    "<br>**Hypothesis** for intercept\n",
    "- H<sub>o</sub>: There is no significant relationship between intercept and y-variable.\n",
    "- H<sub>1</sub>: There is significant relationship between intercept and y-variable.\n",
    "- Conclusion: As the p-value for intercept is 2.85e<sup>-05</sup> we can reject the null hypothesis, i.e there is significant relationship between intercept and y-variable at 95% confidence interval\n",
    "<br>**Hypothesis** for x-variable wheat production\n",
    "- H<sub>o</sub>: There is no significant relationship between intercept and y-variable.\n",
    "- H<sub>1</sub>: There is significant relationship between intercept and y-variable.\n",
    "- Conclusion: As the p-value for wheat production is 0.00198 we can reject the null hypothesis, i.e there is significant relationship between wheat production and flour prices (y-variable) at 95% confidence interval\n",
    "\n",
    "confint(mod_lm,level=0.95)\n",
    "\n",
    "## Q2. Fit the regression line using the method of least squares\n",
    "\n",
    "|Verbal IQ|Brain size|\n",
    "|:-------:|:--------:|\n",
    "|132|816.932|\n",
    "|132|951.545|\n",
    "|90|928.799|\n",
    "\n",
    "verbal_iq = c(132,132,90,136,90,129,120,100,71,132,112,129,86,90,83,126,126,90,129,86)\n",
    "brain_size = c(816.932,951.545,928.799,991.305,854.258,833.868,856.472,878.897,865.363,852.244,\n",
    "               808.02,790.619,831.772,798.612,793.549,866.662,857.782,834.344,948.066,893.983)\n",
    "\n",
    "data <- data.frame(verbal_iq,brain_size)\n",
    "\n",
    "qqnorm(data$brain_size)\n",
    "qqline(data$brain_size)\n",
    "\n",
    "hist(data$brain_size)\n",
    "\n",
    "shapiro.test(data$brain_size)\n",
    "\n",
    "mod <- lm('verbal_iq ~ brain_size',data=data)\n",
    "\n",
    "mod\n",
    "\n",
    "summary(mod)\n",
    "\n",
    "- The Adj R-squared value is ~1.3%, therefore we can say that the model doesn't fit the data well.\n",
    "- The p-value for brain_size is 0.278 and for the intercept is 0.755, therefore we can say that both intercept and brain_size are not significant.\n",
    "- The p-value for the model is 0.278, therefore we can say that the model is not significant.\n",
    "\n",
    "----\n",
    "\n",
    "## Multiple Linear Regression\n",
    "\n",
    "- Multiple linear regression is built from simple linear regression\n",
    "- It is used when we have more than one independent variable\n",
    "- The equation of multiple linear regression is y = b<sub>0</sub> + b<sub>1</sub>x<sub>1</sub> + b<sub>2</sub>x<sub>2</sub>+.....+b<sub>k</sub>x<sub>k</sub>\n",
    "\n",
    "set.seed(123)\n",
    "\n",
    "x <- rnorm(100,mean=1,sd=1)\n",
    "x2 <- rnorm(100,mean=2,sd=5)\n",
    "\n",
    "y <- rnorm(100,mean=2,sd=2)\n",
    "\n",
    "data <- data.frame(x,x2,y)\n",
    "\n",
    "mod <- lm('y ~ x+x2',data=data)\n",
    "\n",
    "mod\n",
    "\n",
    "summary(mod)\n",
    "\n",
    "- y = -0.266343x + 0.009525x2\n",
    "- The p-values are 7.97e<sup>-13</sup>, 0.207, 0.810, 0.4295. The intercept is significant because the p-value is 7.97e<sup>-13</sup>, which is smaller than 0.05\n",
    "\n",
    "## Q1\n",
    "Construct a multiple linear regression model that explores the relationship between blood pressure, weight, height and age.\n",
    "1. How well does the regression model fit the data?\n",
    "2. Check the significance of the beta coefficients.\n",
    "3. Check overall significance of regression model.\n",
    "\n",
    "blood_pressure = c(105,106,108,110,113,115,118,119,120,122)\n",
    "weight = c(75,80,89,90,93,95,96,99,101,102)\n",
    "height = c(172,175,170,174,178,179,180,183,185,188)\n",
    "age = c(19,18,20,20,21,22,24,25,29,30)\n",
    "\n",
    "blood_pressure_data <- data.frame(blood_pressure, weight, height, age)\n",
    "\n",
    "qqnorm(blood_pressure_data$weight)\n",
    "qqline(blood_pressure_data$weight)\n",
    "\n",
    "qqnorm(blood_pressure_data$height)\n",
    "qqline(blood_pressure_data$height)\n",
    "\n",
    "qqnorm(blood_pressure_data$age)\n",
    "qqline(blood_pressure_data$age)\n",
    "\n",
    "shapiro.test(blood_pressure_data$weight)\n",
    "\n",
    "shapiro.test(blood_pressure_data$height)\n",
    "\n",
    "shapiro.test(blood_pressure_data$age)\n",
    "\n",
    "mod_lm = lm('blood_pressure ~ weight+height+age',data=blood_pressure_data)\n",
    "\n",
    "mod_lm\n",
    "\n",
    "summary(mod_lm)\n",
    "\n",
    "- Adj. R-squared score is ~96%, therefore we can say that the regression model fits the data well.\n",
    "- P-value for weight is `0.00564`, height is `0.05161`, age is `0.51022` and intercept is `0.96206`. Only Weight is significant, as their p-values are less than 0.05\n",
    "- The p-value for the model is 2.817e<sup>-05</sup>, therefore we can say that the model is significant.\n",
    "\n",
    "----\n",
    "\n",
    "# Non parametric Test\n",
    "\n",
    "- The non parametric test is a test that does not require the variable and sample to be normally distributed. Most of the time we use parametric tests like the t-test, chi-square test and ANOVA because they are more accurate.\n",
    "- You use non-parametric tests when you do not have normally distributed data and the sample data is big.\n",
    "\n",
    "## Wilcoxon Signed Rank Test\n",
    "\n",
    "- The Wilcoxon signed rank test is used to replace the one-sample t-test.\n",
    "- For each x<sub>i</sub>, for i = 1,2,.....,n the signed difference is d<sub>i</sub> = x<sub>i</sub> - \\mu<sub>0</sub>, where \\mu<sub>0</sub> is the given median.\n",
    "- The null hypothesis is that the population median has the specified value of \\mu<sub>0</sub>.\n",
    "    - Null Hypothesis: H<sub>0</sub> : \\mu = \\mu<sub>0</sub>\n",
    "    - Alternate Hypothesis: H<sub>1</sub> : \\mu != \\mu<sub>0</sub>\n",
    "    \n",
    ".....\n",
    "\n",
    "To use the Wilcoxon signed rank test in R, you can first generate the data using random.org packages, so that the variables are not normally distributed.\n",
    "\n",
    "```\n",
    "install.packages('random')\n",
    "```\n",
    "\n",
    "library(random)\n",
    "\n",
    "var1 <- randomNumbers(n=100,min=1,max=1000,col=1)\n",
    "var2 <- randomNumbers(n=100,min=1,max=1000,col=1)\n",
    "var3 <- randomNumbers(n=100,min=1,max=1000,col=1)\n",
    "\n",
    "n is the number of random numbers, min is the minimum value, max is the maximum value and col is the number of columns for all the numbers.\n",
    "This is the method to generate true random numbers in R. Your data may be different because the data is generated randomly. You can then create the data using\n",
    "\n",
    "data <- data.frame(var1[,1],var2[,1],var3[,1])\n",
    "\n",
    "print(head(data))\n",
    "\n",
    "To use Wilcoxon signed rank test, you can use the wilcox.test() function\n",
    "\n",
    "wilcox.test(data[,1],mu=0,alternatives='two.sided')\n",
    "\n",
    "The p-value is < 2.2e<sup>-16</sup>, which is less than 0.05. Hence, you reject the null hypothesis. There are significant differences in the median for the first variable median and the median of 0. The alternate hypothesis is true at the 95% confidence interval.\n",
    "\n",
    "## R-program to illustrate one-sample Wilcoxon signed rank test\n",
    "\n",
    "set.seed(1234)\n",
    "\n",
    "my_data = data.frame(name=paste0(rep('R_',10),1:10),weight=round(rnorm(10,30,2),1))\n",
    "\n",
    "print(head(my_data))\n",
    "\n",
    "res = wilcox.test(my_data$weight,mu=25)\n",
    "\n",
    "res\n",
    "\n",
    "As the p-value is 0.005793, which is less than 0.05. We can reject the null hypothesis. There are significant differences in the median for the first variable median and the median of 25. The alternate hypothesis is true at the 95% confidence interval.\n",
    "\n",
    "res1 = wilcox.test(my_data$weight,mu=25,alternative = 'less')\n",
    "\n",
    "res1\n",
    "\n",
    "As the p-value is 0.9979, which is more than 0.05. We cannot reject the null hypothesis. There is no significant differences in the median for the first variable median and the median of 25.\n",
    "\n",
    "res2 = wilcox.test(my_data$weight,mu=25,alternative = 'greater')\n",
    "\n",
    "res2\n",
    "\n",
    "As the p-value is 0.002897, which is more than 0.05. We can reject the null hypothesis. The median weight is greater than 25.\n",
    "\n",
    "## Wilcoxon-Mann-Whitney Test\n",
    "\n",
    "var1 <- randomNumbers(100,1,1000,1)\n",
    "var1 <- randomNumbers(100,1,1000,1)\n",
    "var1 <- randomNumbers(100,1,1000,1)\n",
    "\n",
    "data <- data.frame(var1[,1],var2[,1],var3[,1])\n",
    "\n",
    "wilcox.test(data[,1],data[,2],correct=FALSE)\n",
    "\n",
    "The p-value is 0.4703, which is more than 0.05. Hence we can not reject the null hypothesis. There are no significant differences in the median for first variable median and second variable median. The null hypothesis is true at the 95% confidence interval.\n",
    "\n",
    "## Kruskal-Wallis Test\n",
    "\n",
    "The Kruskal-Wallis test is a non parametric test that is an extension of the Mann-Whitney U test for three or more samples. The test requires samples to be identically distributed. Kruskal-Wallis is an alternative to one-way ANOVA. The Kruskal-Wallis test tests the differences between scores of k independent samples of unequal sizes with the i<sup>th</sup> sample containing l<sub>i</sub> rows.\n",
    "\n",
    "data('airquality')\n",
    "\n",
    "kruskal.test(airquality$Ozone ~ airquality$Month)\n",
    "\n",
    "## Q1\n",
    "\n",
    "x = c(12.3,15.4,10.3,8,14.6,15.7,10.8,45,12.3,8.2,20.1,26.3,32.4,41.2,35.1,25,8.2,18.4,32.5)\n",
    "y = c(rep('A',5),rep('B',7),rep('C',7))\n",
    "\n",
    "kruskal.test(x~y)\n",
    "\n",
    "## Q2\n",
    "\n",
    "x = c(166.7,172.2,165,176.9,166.2,157.3,166.7,161.1,158.6,176.4,153.1,156,162.8,142.4,162.7,162.4)\n",
    "y = c(rep('0',4),rep('1',4),rep('3',4),rep('9',4))\n",
    "\n",
    "kruskal.test(x~y)\n",
    "\n",
    "# Friedmann test\n",
    "\n",
    "It is a non-parametric test which is used for three or more samples. It is used when there are two independent samples. It is an alternative of two way anova.\n",
    "<br>Ho : \\muo = \\mu1 = \\mu2 = ... = \\muk\n",
    "<br>Ha: \\mu0 != \\muk\n",
    "<br>\n",
    "\\mu is median\n",
    "\n",
    "obs = c(45,49,38,48,45,39,43,42,35,41,39,36)\n",
    "# obs = c(45,48,43,41,49,45,42,39,38,39,35,36)\n",
    "soyabean_var = c(rep('A',3),rep('B',3),rep('C',3),rep('D',3))\n",
    "block = c(rep(c('1','2','3'),4))\n",
    "\n",
    "df = data.frame(matrix(obs,nrow=3,ncol=4,byrow = TRUE),row.names = c(1,2,3))\n",
    "\n",
    "colnames(df) = c('A','B','C','D')\n",
    "\n",
    "df\n",
    "\n",
    "friedman.test(obs~soyabean_var|block)\n",
    "\n",
    "obs = c(5,7,3,4,3,4,5,5,8,6,7,7,9,2,6,8,2,3,4,3,7,9,10,9,6,8,8,6,1,5,2,1,4,1,1,2,10,10,9,10)\n",
    "students = c(rep('1',4),rep('2',4),rep('3',4),rep('4',4),rep('5',4),rep('6',4),rep('7',4),\n",
    "            rep('8',4),rep('9',4),rep('10',4))\n",
    "prof = c(rep(c(1,2,3,4),10))\n",
    "\n",
    "friedman.test(obs~students|prof)\n",
    "\n",
    "## Q3\n",
    "\n",
    "reaction_time = c(1.21,1.63,1.42,2.43,1.16,1.94,1.48,1.85,2.06,1.98,1.27,2.44,1.56,2.01,1.7,2.64,1.48,2.81)\n",
    "lbl = c(rep('A',6),rep('B',6),rep('C',6))\n",
    "\n",
    "sub = c(rep(c('1','2','3','4','5','6'),3))\n",
    "\n",
    "kruskal.test(reaction_time~lbl)\n",
    "\n",
    "friedman.test(reaction_time~lbl|sub)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
